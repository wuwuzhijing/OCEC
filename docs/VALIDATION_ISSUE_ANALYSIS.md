# 验证集指标几乎不变问题分析

## 问题现象

从训练日志可以看到：

### 训练集指标（正常提升）
- **Epoch 1**: f1=0.5251, recall=0.5092, precision=0.5419
- **Epoch 29**: f1=0.6339, recall=0.6249, precision=0.6432
- ✅ 训练集指标在持续提升，模型在正常学习

### 验证集指标（几乎不变）
- **Epoch 1**: f1=0.6931, recall=0.9969, precision=0.5312
- **Epoch 29**: f1=0.6941, recall=0.9999, precision=0.5316
- ❌ 验证集指标几乎不变，recall接近100%，precision固定在0.53左右

## 关键发现

### 1. 验证集概率分布异常

从日志可以看到验证集的概率分布：

```
Val epoch summary - probs: mean=0.841, std=0.073, median=0.848, q25=0.798, q75=0.891
```

**关键问题**：
- **验证集概率均值**: 0.834-0.841（远高于阈值0.5）
- **训练集概率均值**: 0.499-0.502（接近阈值0.5）
- **验证集概率25分位数**: 0.789-0.798（连25%的样本概率都在0.78以上！）

这意味着**验证集几乎所有的样本都被预测为正类**（pred_pos_ratio: 0.9997-0.9999）。

### 2. 数据划分问题

通过检查脚本发现：

```
⚠️  警告：训练集和验证集包含 1 个相同的视频！
   重叠的视频示例:
     1. unknown: 训练集376648帧, 验证集94163帧
```

**问题**：
- 所有数据都来自同一个视频（"unknown"）
- 训练集和验证集都包含这个视频的帧
- 数据是按**样本随机划分**的，而不是按视频划分的

### 3. 混淆矩阵分析

验证集的混淆矩阵：
- **TP**: ~50045（预测为正，实际为正）
- **TN**: 2-12（预测为负，实际为负）**← 非常少！**
- **FP**: ~44098（预测为正，实际为负）**← 非常多！**
- **FN**: 7-18（预测为负，实际为正）**← 非常少！**

**结论**：模型在验证集上几乎把所有样本都预测为正类。

## 根本原因分析

### 原因1：数据分布不一致

虽然训练集和验证集的**标签比例相同**（都是53.2%正类），但它们的**特征分布可能不同**：

1. **时间相关性**：来自同一个视频的不同时间段，可能具有不同的特征
2. **提取方式**：如果验证集的帧是从视频的不同部分提取的，可能更容易被预测为正类
3. **数据泄漏**：由于是同一个视频，模型可能在训练时"记住"了验证集的特征

### 原因2：阈值设置不合理

当前阈值是 **0.5**，但：
- 验证集概率均值：**0.84**
- 验证集概率中位数：**0.85**
- 验证集概率25分位数：**0.80**

这意味着即使阈值设为0.5，验证集几乎所有的样本都会被预测为正类。

### 原因3：模型过拟合到验证集

由于训练集和验证集来自同一个视频，模型可能：
1. 在训练时"见过"验证集的特征
2. 学习到了验证集特有的模式
3. 导致验证集性能被高估

## 解决方案

### 方案1：重新划分数据（推荐）

**按视频划分**，而不是按样本随机划分：

```python
# 修改 04_dataset_convert_to_parquet.py 中的 stratified_split 函数
def stratified_split_by_video(df, train_ratio, seed):
    # 按视频分组
    video_groups = {}
    for video_name, group in df.groupby("source"):
        video_groups[video_name] = group
    
    # 随机打乱视频列表
    video_list = list(video_groups.keys())
    random.shuffle(video_list)
    
    # 按比例划分视频
    n_train_videos = int(len(video_list) * train_ratio)
    train_videos = set(video_list[:n_train_videos])
    
    # 收集训练集和验证集的样本
    train_rows = []
    val_rows = []
    for video_name, group in video_groups.items():
        if video_name in train_videos:
            train_rows.extend(group.to_dict(orient="records"))
        else:
            val_rows.extend(group.to_dict(orient="records"))
    
    return pd.DataFrame(train_rows), pd.DataFrame(val_rows)
```

**注意**：如果所有数据都来自同一个视频（"unknown"），这个方案无法解决根本问题。需要：
1. 检查数据来源，确保有多个不同的视频
2. 或者按其他方式划分（如按时间、按场景等）

### 方案2：调整阈值

根据验证集的概率分布，调整阈值：

```python
# 当前阈值
CONF_THRESHOLD = 0.5

# 建议阈值（基于验证集概率分布）
# 如果验证集概率均值是0.84，可以尝试：
CONF_THRESHOLD = 0.75  # 或更高
```

但这只是**治标不治本**，不能解决数据分布不一致的问题。

### 方案3：使用Focal Loss

Focal Loss 可以：
1. 降低易分类样本的权重
2. 提高难分类样本的权重
3. 可能有助于平衡训练集和验证集的分布差异

但需要确保概率计算的一致性（之前已经修复）。

### 方案4：检查数据质量

1. **检查数据来源**：确认是否有多个不同的视频
2. **检查标签质量**：验证集的标签是否正确
3. **检查特征分布**：比较训练集和验证集的图像特征分布

## 当前状态总结

| 指标 | 训练集 | 验证集 | 问题 |
|------|--------|--------|------|
| **F1** | 0.5251 → 0.6339 ✅ | 0.6931 → 0.6941 ❌ | 验证集几乎不变 |
| **Recall** | 0.5092 → 0.6249 ✅ | 0.9969 → 0.9999 ❌ | 验证集接近100% |
| **Precision** | 0.5419 → 0.6432 ✅ | 0.5312 → 0.5316 ❌ | 验证集几乎不变 |
| **概率均值** | 0.499-0.502 ✅ | 0.834-0.841 ❌ | 验证集概率异常高 |
| **预测正例比例** | 0.499-0.515 ✅ | 0.9997-0.9999 ❌ | 验证集几乎全预测为正类 |

## 建议的下一步

1. **立即检查数据来源**：
   - 确认是否有多个不同的视频
   - 如果只有一个视频，需要重新收集数据或按其他方式划分

2. **如果数据来源正常**：
   - 重新划分数据，使用按视频划分的方式
   - 重新训练模型

3. **如果数据来源有问题**：
   - 考虑按时间、按场景、按其他特征划分
   - 或者收集更多不同来源的数据

4. **临时措施**：
   - 可以尝试调整阈值，但这不是根本解决方案
   - 可以尝试使用Focal Loss，但需要确保概率计算的一致性

## 结论

验证集指标几乎不变的根本原因是：
1. **数据划分方式不合理**：按样本随机划分，导致训练集和验证集数据分布不一致
2. **数据来源单一**：所有数据来自同一个视频，无法真正按视频划分
3. **阈值设置不合理**：当前阈值0.5对于验证集的概率分布来说太低

**最关键的解决方案是重新划分数据，确保训练集和验证集的数据分布一致。**

