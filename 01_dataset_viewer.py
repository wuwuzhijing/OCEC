#!/usr/bin/env python3
"""
Hugging Face Dataset Viewer (OpenCV version)
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: MichalMlodawski/closed-open-eyes
- Parquetå½¢å¼ã§ä¿å­˜ (data/{split}/train.parquet)
- æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å†åˆ©ç”¨
- OpenCVã§ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒ«ã‚’å¯è¦–åŒ–
"""

import argparse
import io
import json
import os
import random
from pathlib import Path
import cv2
import numpy as np
from PIL import Image
from datasets import load_dataset, Dataset
import requests


def resolve_image(image_data):
    """Image-likeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’RGBã®PIL.Imageã«å¤‰æ›ã—ã¦è¿”ã™"""
    img = None

    if isinstance(image_data, dict):
        file_info = image_data.get("file")

        if isinstance(file_info, Image.Image):
            img = file_info

        elif isinstance(file_info, bytes):
            # äºŒè¿›åˆ¶æ•°æ®ï¼ˆä» parquet æ–‡ä»¶ä¸­è¯»å–ï¼‰
            try:
                img = Image.open(io.BytesIO(file_info))
            except Exception as e:
                print(f"[WARN] Could not decode image from bytes: {e}")

        elif isinstance(file_info, str) and os.path.exists(file_info):
            try:
                img = Image.open(file_info)
            except Exception as e:
                print(f"[WARN] Could not open local image '{file_info}': {e}")

        elif isinstance(file_info, dict) and "src" in file_info:
            url = file_info["src"]
            try:
                res = requests.get(url, timeout=10)
                res.raise_for_status()
                img = Image.open(io.BytesIO(res.content))
            except Exception as e:
                print(f"[WARN] Could not load from URL '{url}': {e}")

    elif isinstance(image_data, Image.Image):
        img = image_data

    elif isinstance(image_data, bytes):
        # ç›´æ¥ä¼ å…¥äºŒè¿›åˆ¶æ•°æ®
        try:
            img = Image.open(io.BytesIO(image_data))
        except Exception as e:
            print(f"[WARN] Could not decode image from bytes: {e}")

    if img is None:
        return None

    if img.mode != "RGB":
        return img.convert("RGB")

    return img.copy()


def visualize_with_opencv(dataset, sample_count: int = 6, output_dir: str = "visualization_output"):
    """OpenCVã‚’ä½¿ã£ã¦ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒ«ã‚’å¯è¦–åŒ–ã—ã¦ä¿å­˜"""
    indices = random.sample(range(len(dataset)), min(sample_count, len(dataset)))
    print(f"ğŸ‘ Saving {len(indices)} random samples to {output_dir}...")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    saved_count = 0
    for i, idx in enumerate(indices):
        record = dataset[idx]
        label = record.get("Label", "unknown")
        image_data = record.get("Image_data")
        img = resolve_image(image_data)

        if img is None:
            print(f"[WARN] Skipping index {idx}, no image data found.")
            continue

        # PIL â†’ OpenCVå½¢å¼ï¼ˆnumpy BGRï¼‰
        img_np = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)

        # ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆæç”»
        cv2.putText(img_np, f"Label: {label}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2, cv2.LINE_AA)

        # ç›®ã®åå¿œï¼ˆåº§æ¨™ï¼‰ã‹ã‚‰ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
        height, width = img_np.shape[:2]

        def draw_react_box(box, color, title):
            if not isinstance(box, (list, tuple)) or len(box) != 4:
                return
            x, y, w, h = box
            if w is None or h is None:
                return
            if w <= 0 or h <= 0:
                return
            x1 = int(round(x))
            y1 = int(round(y))
            x2 = int(round(x + w))
            y2 = int(round(y + h))
            x1 = max(0, min(width - 1, x1))
            y1 = max(0, min(height - 1, y1))
            x2 = max(0, min(width - 1, x2))
            y2 = max(0, min(height - 1, y2))
            if x2 <= x1 or y2 <= y1:
                return
            cv2.rectangle(img_np, (x1, y1), (x2, y2), color, 2)
            text_pos = (x1, max(0, y1 - 10))
            cv2.putText(img_np, title, text_pos,
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2, cv2.LINE_AA)

        draw_react_box(record.get("Left_eye_react"), (0, 255, 255), "Left eye")
        draw_react_box(record.get("Right_eye_react"), (255, 0, 0), "Right eye")

        # ä¿å­˜å›¾åƒåˆ°æœ¬åœ°
        image_id = record.get("Image_id", idx)
        filename = f"sample_{i+1:03d}_idx_{idx}_id_{image_id}_label_{label}.jpg"
        filepath = output_path / filename
        
        try:
            cv2.imwrite(str(filepath), img_np)
            saved_count += 1
            print(f"  âœ… Saved: {filename}")
        except Exception as e:
            print(f"  âš ï¸  Failed to save {filename}: {e}")

    print(f"âœ… Saved {saved_count}/{len(indices)} samples to {output_path}")


def extract_dataset(dataset, base_outdir: str, split: str):
    """Parquetã«å«ã¾ã‚Œã‚‹ç”»åƒã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ‡ã‚£ã‚¹ã‚¯ã¸å±•é–‹"""
    extract_root = Path(base_outdir) / "extracted" / split
    total = len(dataset)
    print(f"ğŸ“¤ Extracting {total} samples to {extract_root} ...")

    extracted_count = 0
    created_chunks = set()

    for idx, record in enumerate(dataset):
        img = resolve_image(record.get("Image_data"))
        if img is None:
            print(f"[WARN] Skipping extraction for index {idx}, no image data found.")
            continue

        extracted_count += 1
        base_name = f"{extracted_count:08d}"
        chunk_index = (extracted_count - 1) // 1000 + 1
        chunk_name = f"{chunk_index:08d}"
        chunk_dir = extract_root / chunk_name

        if chunk_name not in created_chunks:
            chunk_dir.mkdir(parents=True, exist_ok=True)
            created_chunks.add(chunk_name)

        image_data = record.get("Image_data")
        ext = ".png"
        if isinstance(image_data, dict):
            filename = image_data.get("filename")
            if filename:
                _, orig_ext = os.path.splitext(filename)
                if orig_ext:
                    ext = orig_ext.lower()

        if ext == ".jpeg":
            ext = ".jpg"
        if ext not in (".jpg", ".png"):
            ext = ".png"

        candidate = chunk_dir / f"{base_name}{ext}"

        save_format = "PNG"
        if ext == ".jpg":
            save_format = "JPEG"

        try:
            img.save(candidate, format=save_format)
        except Exception as e:
            print(f"[WARN] Failed to save image for index {idx}: {e}")
            continue

        annotation = {
            "image_filename": candidate.name,
            "image_id": record.get("Image_id"),
            "label": record.get("Label"),
            "left_eye_react": record.get("Left_eye_react"),
            "right_eye_react": record.get("Right_eye_react"),
            "split": split,
        }
        ann_path = chunk_dir / f"{base_name}.json"
        try:
            with ann_path.open("w", encoding="utf-8") as f:
                json.dump(annotation, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[WARN] Failed to write annotation for index {idx}: {e}")

        if (idx + 1) % 1000 == 0 or (idx + 1) == total:
            print(f"  - Processed {idx + 1}/{total}, saved {extracted_count}")


def main():
    parser = argparse.ArgumentParser(description="Download and visualize MichalMlodawski/closed-open-eyes dataset with OpenCV.")
    parser.add_argument("--split", type=str, default="train", help="Dataset split (default: train)")
    parser.add_argument("--visualize", action="store_true", help="Visualize random samples and save to local files")
    parser.add_argument("--sample-count", type=int, default=6, help="Number of samples to visualize")
    parser.add_argument("--visualize-output", type=str, default="visualization_output", help="Output directory for visualized images (default: ./visualization_output)")
    parser.add_argument("--outdir", type=str, default="data", help="Output directory for extracted images (default: ./data)")
    parser.add_argument("--force", action="store_true", help="Force re-download even if parquet exists")
    parser.add_argument("--extract", action="store_true", help="Extract images and annotations to --outdir/extracted/{split}")
    parser.add_argument("--dataset-path", type=str, default="/ssddisk/guochuang/ocec/data", 
                        help="Path to local dataset directory containing parquet files (default: /ssddisk/guochuang/ocec/data)")
    args = parser.parse_args()

    split = args.split
    ds = None
    dataset_loaded = False

    # --- ä¼˜å…ˆæ£€æŸ¥æœ¬åœ°æ•°æ®é›†è·¯å¾„ ---
    dataset_path = Path(args.dataset_path)
    if dataset_path.exists() and dataset_path.is_dir():
        # æŸ¥æ‰¾ dataset_*.parquet æ–‡ä»¶ï¼ˆHugging Face ä¸‹è½½çš„æ ¼å¼ï¼‰
        parquet_files = sorted(dataset_path.glob("dataset_*.parquet"))
        if parquet_files:
            print(f"âœ… Found local dataset directory: {dataset_path}")
            print(f"ğŸ“– Found {len(parquet_files)} parquet files (dataset_*.parquet)")
            print(f"ğŸ“– Loading dataset from multiple parquet files...")
            try:
                # ä½¿ç”¨é€šé…ç¬¦æ¨¡å¼åŠ è½½æ‰€æœ‰ parquet æ–‡ä»¶
                parquet_pattern = str(dataset_path / "dataset_*.parquet")
                ds = Dataset.from_parquet(parquet_pattern)
                print(f"âœ… Loaded {len(ds)} samples from {len(parquet_files)} parquet files")
                dataset_loaded = True
            except Exception as e:
                print(f"âš ï¸  Failed to load dataset from parquet files: {e}")
                print(f"ğŸ“¦ Falling back to download...")
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ° dataset_*.parquetï¼Œå°è¯•æŸ¥æ‰¾å•ä¸ª {split}.parquet
            parquet_file = dataset_path / f"{split}.parquet"
            if parquet_file.exists():
                print(f"âœ… Found local dataset file: {parquet_file}")
                print(f"ğŸ“– Loading dataset from {parquet_file}...")
                try:
                    ds = Dataset.from_parquet(str(parquet_file))
                    print(f"âœ… Loaded {len(ds)} samples from local file")
                    dataset_loaded = True
                except Exception as e:
                    print(f"âš ï¸  Failed to load dataset from {parquet_file}: {e}")
                    print(f"ğŸ“¦ Falling back to download...")
            else:
                print(f"âš ï¸  Directory {dataset_path} exists but no parquet files found.")
                print(f"   Looking for: dataset_*.parquet or {split}.parquet")
                print(f"ğŸ“¦ Falling back to download...")
    elif dataset_path.exists() and dataset_path.is_file() and dataset_path.suffix == '.parquet':
        # ç›´æ¥æŒ‡å®šäº†å•ä¸ª parquet æ–‡ä»¶
        print(f"âœ… Found local dataset file: {dataset_path}")
        print("ğŸ“– Loading dataset from specified parquet file...")
        try:
            ds = Dataset.from_parquet(str(dataset_path))
            print(f"âœ… Loaded {len(ds)} samples from local file")
            dataset_loaded = True
        except Exception as e:
            print(f"âš ï¸  Failed to load dataset from {dataset_path}: {e}")
            print(f"ğŸ“¦ Falling back to download...")

    # --- å¦‚æœæœ¬åœ°åŠ è½½å¤±è´¥ï¼Œå°è¯•ä»ç½‘ä¸Šä¸‹è½½ ---
    if not dataset_loaded:
        if args.force:
            print("âš ï¸  Force mode enabled. Re-downloading dataset...")
        print(f"ğŸ“¦ Downloading dataset split='{split}' from Hugging Face...")
        try:
            ds = load_dataset("MichalMlodawski/closed-open-eyes", split=split)
            print(f"âœ… Loaded {len(ds)} samples")
            
            # ä¿å­˜åˆ°æœ¬åœ°ï¼ˆå¯é€‰ï¼‰
            outdir = os.path.join(args.outdir, split)
            os.makedirs(outdir, exist_ok=True)
            parquet_path = os.path.join(outdir, f"{split}.parquet")
            print(f"ğŸ’¾ Saving dataset to {parquet_path} ...")
            ds.to_parquet(parquet_path)
            print(f"âœ… Saved parquet: {parquet_path}")
        except Exception as e:
            print(f"âŒ Failed to download dataset: {e}")
            return

    if args.extract:
        extract_dataset(ds, args.outdir, split)

    if args.visualize:
        visualize_with_opencv(ds, args.sample_count, args.visualize_output)
    elif not args.extract:
        print("ğŸ‘ Visualization disabled. Use --visualize to enable.")


if __name__ == "__main__":
    main()
